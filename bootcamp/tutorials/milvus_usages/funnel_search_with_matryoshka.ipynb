{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funnel Search with Matryoshka Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit the example from the [Milvus and Sentence Transformers doc](???) of semantic search on the Wikipedia Movie Plots dataset. First our imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymilvus\n",
    "from pymilvus import MilvusClient, connections\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Matryoshka Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using the regular embedding model [`sentence-transformers/all-MiniLM-L12-v2`](https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2) as in the previous example, we use [a model from Nomic](https://huggingface.co/nomic-ai/nomic-embed-text-v1) trained to produce Matryoshka embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\n",
    "    \"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True, device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset, Embedding Items, and Building Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll abbreviate the discussion of loading and embeddings the data - refer to the docs for more details. Two changes we have made are changing the embedding dimension and adding a prefix to the document embeddings, which is a requirement from how the model was trained.\n",
    "\n",
    "Milvus does not currently support searching over subsets of embeddings, so we break the embeddings into two parts: the head represents the initial subset of the vector to index and search, and the tail is the remainder. The model is trained for cosine distance similarity search, so we normalize the head embeddings. However, in order to calculate similarities for larger subsets later on, we need to store the norm of the head embedding, so we can unnormalize it before joining to the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast', 'Genre', 'Wiki Page', 'Plot', 'PlotSummary'],\n",
      "    num_rows: 34886\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [06:31<00:00,  5.67s/it]\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 768\n",
    "search_dim = 128\n",
    "collection_name = \"movie_embeddings\"\n",
    "\n",
    "ds = load_dataset(\"vishnupriyavr/wiki-movie-plots-with-summaries\", split=\"train\")\n",
    "print(ds)\n",
    "\n",
    "client = MilvusClient(uri=\"./wiki-movie-plots-matryoshka.db\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=256),\n",
    "    FieldSchema(name=\"head_embedding\", dtype=DataType.FLOAT_VECTOR, dim=search_dim),\n",
    "    FieldSchema(name=\"head_norm\", dtype=DataType.FLOAT),\n",
    "    FieldSchema(\n",
    "        name=\"tail_embedding\",\n",
    "        dtype=DataType.FLOAT_VECTOR,\n",
    "        dim=embedding_dim - search_dim,\n",
    "    ),\n",
    "    # These fields are not used for funnel search, only for comparing to alternative methods\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),\n",
    "    FieldSchema(\n",
    "        name=\"flip_head_embedding\", dtype=DataType.FLOAT_VECTOR, dim=search_dim\n",
    "    ),\n",
    "    FieldSchema(name=\"flip_head_norm\", dtype=DataType.FLOAT),\n",
    "    FieldSchema(\n",
    "        name=\"flip_tail_embedding\",\n",
    "        dtype=DataType.FLOAT_VECTOR,\n",
    "        dim=embedding_dim - search_dim,\n",
    "    ),\n",
    "]\n",
    "\n",
    "schema = CollectionSchema(fields=fields, enable_dynamic_field=False)\n",
    "client.create_collection(collection_name=collection_name, schema=schema)\n",
    "\n",
    "index_params = client.prepare_index_params()\n",
    "index_params.add_index(field_name=\"head_embedding\", index_type=\"FLAT\", metric_type=\"IP\")\n",
    "index_params.add_index(field_name=\"embedding\", index_type=\"FLAT\", metric_type=\"IP\")\n",
    "index_params.add_index(\n",
    "    field_name=\"flip_head_embedding\", index_type=\"FLAT\", metric_type=\"IP\"\n",
    ")\n",
    "client.create_index(collection_name, index_params)\n",
    "\n",
    "for batch in tqdm(ds.batch(batch_size=512)):\n",
    "    plot_summary = [\"search_document: \" + x.strip() for x in batch[\"PlotSummary\"]]\n",
    "    embeddings = model.encode(plot_summary, convert_to_tensor=True)\n",
    "\n",
    "    # Solely for valid funnel search\n",
    "    head_embeddings = embeddings[:, :search_dim]\n",
    "    head_norms = torch.linalg.vector_norm(head_embeddings, dim=1)\n",
    "    head_embeddings = F.normalize(head_embeddings, p=2, dim=1)\n",
    "    tail_embeddings = embeddings[:, search_dim:]\n",
    "\n",
    "    # For method comparison\n",
    "    embeddings_normed = F.normalize(embeddings, p=2, dim=1)\n",
    "    flip_embeddings = torch.flip(embeddings, [1])\n",
    "    flip_head_embeddings = flip_embeddings[:, :search_dim]\n",
    "    flip_head_norms = torch.linalg.vector_norm(flip_head_embeddings, dim=1)\n",
    "    flip_head_embeddings = F.normalize(flip_head_embeddings, p=2, dim=1)\n",
    "    flip_tail_embeddings = flip_embeddings[:, search_dim:]\n",
    "\n",
    "    data = [\n",
    "        {\n",
    "            \"title\": title,\n",
    "            \"head_embedding\": head.cpu().numpy(),\n",
    "            \"head_norm\": float(head_norm),\n",
    "            \"tail_embedding\": tail.cpu().numpy(),\n",
    "            # For method comparison\n",
    "            \"embedding\": embedding.cpu().numpy(),\n",
    "            \"flip_head_embedding\": flip_head.cpu().numpy(),\n",
    "            \"flip_head_norm\": float(flip_head_norm),\n",
    "            \"flip_tail_embedding\": flip_tail.cpu().numpy(),\n",
    "        }\n",
    "        for title, head, head_norm, tail, embedding, flip_head, flip_head_norm, flip_tail in zip(\n",
    "            batch[\"Title\"],\n",
    "            head_embeddings,\n",
    "            head_norms,\n",
    "            tail_embeddings,\n",
    "            embeddings_normed,\n",
    "            flip_head_embeddings,\n",
    "            flip_head_norms,\n",
    "            flip_tail_embeddings,\n",
    "        )\n",
    "    ]\n",
    "    res = client.insert(collection_name=collection_name, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Funnel Search\n",
    "Let's now implement a \"funnel search\" using the smaller part of the Matryoshka embeddings. In the process, we will also obtain results for a search that just uses the smaller part of the embeddings without performing score, re-rank, prune operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"A movie about a shark that terrorizes an LA beach.\",\n",
    "    \"An archaeologist searches for ancient artifacts while fighting Nazis.\",\n",
    "    \"Teenagers in detention learn about themselves.\",\n",
    "    \"A teenager fakes illness to get off school and have adventures with two friends.\",\n",
    "    \"A young couple with a kid look after a hotel during winter and the husband goes insane.\",\n",
    "    \"Four turtles fight bad guys.\",\n",
    "]\n",
    "\n",
    "\n",
    "# Search the database based on input text\n",
    "def embed_search(data):\n",
    "    embeds = model.encode(data)\n",
    "    return [x for x in embeds]\n",
    "\n",
    "\n",
    "instruct_queries = [\"search_query: \" + q.strip() for q in queries]\n",
    "search_data = embed_search(instruct_queries)\n",
    "\n",
    "# Normalize head embeddings\n",
    "head_search = [x[:search_dim] / np.linalg.norm(x[:search_dim]) for x in search_data]\n",
    "\n",
    "# Perform standard vector search on subset of embeddings\n",
    "res = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=head_search,\n",
    "    anns_field=\"head_embedding\",\n",
    "    limit=128,\n",
    "    output_fields=[\"title\", \"head_embedding\", \"head_norm\", \"tail_embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll print the search results before performing the funnel operations for comparison to the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A movie about a shark that terrorizes an LA beach.\n",
      "Results:\n",
      "The Shallows\n",
      "Bait 3D\n",
      "Tintorera\n",
      "2-Headed Shark Attack\n",
      "The Life Aquatic with Steve Zissou\n",
      "Tiger Shark\n",
      "Deliver Us from Evil\n",
      "\n",
      "Query: An archaeologist searches for ancient artifacts while fighting Nazis.\n",
      "Results:\n",
      "\"Pimpernel\" Smith\n",
      "Black Hunters\n",
      "The Passage\n",
      "Counterblast\n",
      "Dominion: Prequel to the Exorcist\n",
      "A Yank in Libya\n",
      "Charlie Chan in Egypt\n",
      "\n",
      "Query: Teenagers in detention learn about themselves.\n",
      "Results:\n",
      "18\n",
      "Dusari Goshta\n",
      "Bad Kids Go to Hell\n",
      "Amar Bondhu Rashed\n",
      "Punishment Park\n",
      "For You I Die\n",
      "Nowhere to Run\n",
      "\n",
      "Query: A teenager fakes illness to get off school and have adventures with two friends.\n",
      "Results:\n",
      "How to Deal\n",
      "Shorts\n",
      "Blackbird\n",
      "Valentine\n",
      "Unfriended\n",
      "Dear Friends\n",
      "Texas Chainsaw Massacre: The Next Generation\n",
      "\n",
      "Query: A young couple with a kid look after a hotel during winter and the husband goes insane.\n",
      "Results:\n",
      "Ghostkeeper\n",
      "Our Vines Have Tender Grapes\n",
      "The Ref\n",
      "Impact\n",
      "The House in Marsh Road\n",
      "Daddy's Home 2\n",
      "Tyrannosaur\n",
      "\n",
      "Query: Four turtles fight bad guys.\n",
      "Results:\n",
      "Teenage Mutant Ninja Turtles II: The Secret of the Ooze\n",
      "Teenage Mutant Ninja Turtles III\n",
      "TMNT 2: Out of the Shadows\n",
      "Gamera: Super Monster\n",
      "Holy Weapon\n",
      "Evil Cat\n",
      "TerrorVision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query, hits in zip(queries, res):\n",
    "    rows = [x['entity'] for x in hits][:7]\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Results:\")\n",
    "    for row in rows:\n",
    "        print(row['title'].strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of exposition of the funnel search algorithm, we convert the Milvus search hits for each query into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_to_dataframe(hits: pymilvus.client.abstract.Hits) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a Milvus search result to a Pandas dataframe. This function is specific to our data schema.\n",
    "\n",
    "    NOTE: We have to unnormalize head embedding so we can correctly normalize superset Matryoshka embeddings. This\n",
    "    is why we stored head_norm field.\n",
    "    \"\"\"\n",
    "    rows = [x['entity'] for x in hits]\n",
    "    rows_dict = [\n",
    "        {\n",
    "            \"title\": x['title'],\n",
    "            \"embedding\": torch.concat(\n",
    "                [\n",
    "                    torch.tensor(x['head_embedding']) * x['head_norm'],\n",
    "                    torch.tensor(x['tail_embedding']),\n",
    "                ],\n",
    "                dim=0,\n",
    "            ),\n",
    "        }\n",
    "        for x in rows\n",
    "    ]\n",
    "    return pd.DataFrame.from_records(rows_dict)\n",
    "\n",
    "\n",
    "dfs = [hits_to_dataframe(hits) for hits in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shallows</td>\n",
       "      <td>[tensor(0.9796), tensor(0.3610), tensor(-3.848...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bait 3D</td>\n",
       "      <td>[tensor(-0.2942), tensor(0.3814), tensor(-4.21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tintorera</td>\n",
       "      <td>[tensor(0.6867), tensor(0.7650), tensor(-4.588...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-Headed Shark Attack</td>\n",
       "      <td>[tensor(-0.4027), tensor(0.9793), tensor(-3.92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Life Aquatic with Steve Zissou</td>\n",
       "      <td>[tensor(-0.1876), tensor(0.8757), tensor(-4.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Meatballs Part II</td>\n",
       "      <td>[tensor(-0.7218), tensor(0.5323), tensor(-3.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Ravana Desam</td>\n",
       "      <td>[tensor(0.3206), tensor(0.0211), tensor(-3.998...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Combat Shock</td>\n",
       "      <td>[tensor(-0.3900), tensor(-0.1212), tensor(-4.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Three Godfathers</td>\n",
       "      <td>[tensor(-1.1591), tensor(-0.2948), tensor(-4.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Rendition</td>\n",
       "      <td>[tensor(0.1849), tensor(0.7475), tensor(-4.057...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "0                          The Shallows   \n",
       "1                               Bait 3D   \n",
       "2                             Tintorera   \n",
       "3                 2-Headed Shark Attack   \n",
       "4    The Life Aquatic with Steve Zissou   \n",
       "..                                  ...   \n",
       "123                   Meatballs Part II   \n",
       "124                        Ravana Desam   \n",
       "125                        Combat Shock   \n",
       "126                    Three Godfathers   \n",
       "127                           Rendition   \n",
       "\n",
       "                                             embedding  \n",
       "0    [tensor(0.9796), tensor(0.3610), tensor(-3.848...  \n",
       "1    [tensor(-0.2942), tensor(0.3814), tensor(-4.21...  \n",
       "2    [tensor(0.6867), tensor(0.7650), tensor(-4.588...  \n",
       "3    [tensor(-0.4027), tensor(0.9793), tensor(-3.92...  \n",
       "4    [tensor(-0.1876), tensor(0.8757), tensor(-4.20...  \n",
       "..                                                 ...  \n",
       "123  [tensor(-0.7218), tensor(0.5323), tensor(-3.96...  \n",
       "124  [tensor(0.3206), tensor(0.0211), tensor(-3.998...  \n",
       "125  [tensor(-0.3900), tensor(-0.1212), tensor(-4.4...  \n",
       "126  [tensor(-1.1591), tensor(-0.2948), tensor(-4.4...  \n",
       "127  [tensor(0.1849), tensor(0.7475), tensor(-4.057...  \n",
       "\n",
       "[128 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to perform funnel search we iterate over the increasingly larger subsets of the vectors on which we we would like to perform a reranking plus pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/3304308004.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n"
     ]
    }
   ],
   "source": [
    "# An optimized implementation would vectorize the calculation of similarity scores across rows (using a matrix)\n",
    "def calculate_score(row, query_emb=None, dims=768):\n",
    "    emb = F.normalize(row[\"embedding\"][:dims], dim=-1)\n",
    "    return (emb @ query_emb).item()\n",
    "\n",
    "\n",
    "# You could also add a top-K parameter as a termination condition\n",
    "def funnel_search(\n",
    "    df: pd.DataFrame, query_emb, scales=[256, 512, 768], prune_ratio=0.5\n",
    ") -> pd.DataFrame:\n",
    "    for dims in scales:\n",
    "        # Query vector must be normalized for each new dimensionality\n",
    "        # query_emb = torch.tensor(search_data[0][:dims] / np.linalg.norm(search_data[0][:dims]))\n",
    "        emb = torch.tensor(query_emb[:dims] / np.linalg.norm(query_emb[:dims]))\n",
    "\n",
    "        # Score\n",
    "        scores = df.apply(\n",
    "            functools.partial(calculate_score, query_emb=emb, dims=dims), axis=1\n",
    "        )\n",
    "        df[\"scores\"] = scores\n",
    "\n",
    "        # Re-rank\n",
    "        df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
    "        df.head()\n",
    "\n",
    "        # Prune (in our case, remove half of candidates at each step)\n",
    "        df = df.head(int(prune_ratio * len(df)))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "dfs_results = [\n",
    "    {\"query\": query, \"results\": funnel_search(df, query_emb)}\n",
    "    for query, df, query_emb in zip(queries, dfs, search_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A movie about a shark that terrorizes an LA beach. \n",
      " 0                           The Shallows\n",
      "3                  2-Headed Shark Attack\n",
      "1                                Bait 3D\n",
      "14                     Jaws: The Revenge\n",
      "4     The Life Aquatic with Steve Zissou\n",
      "69                                  Jaws\n",
      "2                              Tintorera\n",
      "Name: title, dtype: object \n",
      "\n",
      "An archaeologist searches for ancient artifacts while fighting Nazis. \n",
      " 0            \"Pimpernel\" Smith\n",
      "1                Black Hunters\n",
      "29     Raiders of the Lost Ark\n",
      "34              The Master Key\n",
      "51             My Gun Is Quick\n",
      "2                  The Passage\n",
      "109                   Primeval\n",
      "Name: title, dtype: object \n",
      "\n",
      "Teenagers in detention learn about themselves. \n",
      " 9            The Breakfast Club\n",
      "100    The Explosive Generation\n",
      "2           Bad Kids Go to Hell\n",
      "11             Bratz: The Movie\n",
      "39             Band of the Hand\n",
      "72               Up the Academy\n",
      "26                 Jail Busters\n",
      "Name: title, dtype: object \n",
      "\n",
      "A teenager fakes illness to get off school and have adventures with two friends. \n",
      " 21               How I Live Now\n",
      "32     On the Edge of Innocence\n",
      "77             Bratz: The Movie\n",
      "4                    Unfriended\n",
      "108                  Simon Says\n",
      "1                        Shorts\n",
      "5                  Dear Friends\n",
      "Name: title, dtype: object \n",
      "\n",
      "A young couple with a kid look after a hotel during winter and the husband goes insane. \n",
      " 9                        The Shining\n",
      "0                        Ghostkeeper\n",
      "11                    Fast and Loose\n",
      "7                     Killing Ground\n",
      "12                        Home Alone\n",
      "31    Home Alone 2: Lost in New York\n",
      "74               Leopard in the Snow\n",
      "Name: title, dtype: object \n",
      "\n",
      "Four turtles fight bad guys. \n",
      " 1                      Teenage Mutant Ninja Turtles III\n",
      "2                            TMNT 2: Out of the Shadows\n",
      "0     Teenage Mutant Ninja Turtles II: The Secret of...\n",
      "7                          Teenage Mutant Ninja Turtles\n",
      "25                                         Dreamcatcher\n",
      "12                                      Kung Fu Panda 2\n",
      "29                                        Kung Fu Panda\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dfs_results:\n",
    "    print(d[\"query\"], \"\\n\", d[\"results\"][:7][\"title\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualitatively, these results seem to have higher recall than the standard vector search in the tutorial, [\"Movie Search using Milvus and Sentence Transformers\"](https://milvus.io/docs/integrate_with_sentencetransformers.md), which uses a different embedding model. (See the paper [Matryoshka](https://arxiv.org/abs/2205.13147) for further experiments and benchmarking.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Funnel Search to Regular Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results of our funnel search to a standard vector search *on the same dataset with the same embedding model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize head embeddings\n",
    "search_embs = [x / np.linalg.norm(x) for x in search_data]\n",
    "\n",
    "# Perform standard vector search on subset of embeddings\n",
    "res = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=search_embs,\n",
    "    anns_field=\"embedding\",\n",
    "    limit=16,\n",
    "    output_fields=[\"title\", \"embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A movie about a shark that terrorizes an LA beach.\n",
      "Results:\n",
      "The Shallows\n",
      "2-Headed Shark Attack\n",
      "Bait 3D\n",
      "Jaws: The Revenge\n",
      "The Life Aquatic with Steve Zissou\n",
      "Jaws\n",
      "Tintorera\n",
      "\n",
      "Query: An archaeologist searches for ancient artifacts while fighting Nazis.\n",
      "Results:\n",
      "\"Pimpernel\" Smith\n",
      "Black Hunters\n",
      "Raiders of the Lost Ark\n",
      "The Master Key\n",
      "My Gun Is Quick\n",
      "The Passage\n",
      "The Mole People\n",
      "\n",
      "Query: Teenagers in detention learn about themselves.\n",
      "Results:\n",
      "The Breakfast Club\n",
      "The Explosive Generation\n",
      "Bad Kids Go to Hell\n",
      "Bratz: The Movie\n",
      "Band of the Hand\n",
      "Up the Academy\n",
      "Jail Busters\n",
      "\n",
      "Query: A teenager fakes illness to get off school and have adventures with two friends.\n",
      "Results:\n",
      "A Walk to Remember\n",
      "Ferris Bueller's Day Off\n",
      "How I Live Now\n",
      "On the Edge of Innocence\n",
      "Bratz: The Movie\n",
      "Unfriended\n",
      "Simon Says\n",
      "\n",
      "Query: A young couple with a kid look after a hotel during winter and the husband goes insane.\n",
      "Results:\n",
      "The Shining\n",
      "Ghostkeeper\n",
      "Fast and Loose\n",
      "Killing Ground\n",
      "Home Alone\n",
      "Home Alone 2: Lost in New York\n",
      "Leopard in the Snow\n",
      "\n",
      "Query: Four turtles fight bad guys.\n",
      "Results:\n",
      "Teenage Mutant Ninja Turtles III\n",
      "TMNT 2: Out of the Shadows\n",
      "Teenage Mutant Ninja Turtles II: The Secret of the Ooze\n",
      "Teenage Mutant Ninja Turtles\n",
      "Dreamcatcher\n",
      "Teenage Mutant Nina Turtles\n",
      "Kung Fu Panda 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query, hits in zip(queries, res):\n",
    "    rows = [x['entity'] for x in hits][:7]\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    print(\"Results:\")\n",
    "    for row in rows:\n",
    "        print(row['title'].strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of the results for \"A teenager fakes illness to get off school...\", the results under funnel search are almost identical to the full search, even though the funnel search was performed on a search space of 128 dimensions vs 768 dimensions for the regular one.\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does the order matter? Suffix vs prefix embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was trained to perform well matching recursively smaller prefixes of the embeddings. Does the order of the dimensions we use matter? For instance, could we also take subsets of the embeddings that are suffixes? In this experiment, we reverse the order of the dimensions in the Matryoshka embeddings and perform a funnel search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize head embeddings\n",
    "flip_search_data = [torch.flip(torch.tensor(x), dims=[-1]).cpu().numpy() for x in search_data]\n",
    "flip_head_search = [x[:search_dim] / np.linalg.norm(x[:search_dim]) for x in flip_search_data]\n",
    "\n",
    "# Perform standard vector search on subset of embeddings\n",
    "res = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=flip_head_search,\n",
    "    anns_field=\"flip_head_embedding\",\n",
    "    limit=128,\n",
    "    output_fields=[\"title\", \"flip_head_embedding\", \"flip_head_norm\", \"flip_tail_embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_to_dataframe(hits: pymilvus.client.abstract.Hits) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a Milvus search result to a Pandas dataframe. This function is specific to our data schema.\n",
    "\n",
    "    NOTE: We have to unnormalize head embedding so we can correctly normalize superset Matryoshka embeddings. This\n",
    "    is why we stored head_norm field.\n",
    "    \"\"\"\n",
    "    rows = [x['entity'] for x in hits]\n",
    "    rows_dict = [\n",
    "        {\n",
    "            \"title\": x['title'],\n",
    "            \"embedding\": torch.concat(\n",
    "                [\n",
    "                    torch.tensor(x['flip_head_embedding']) * x['flip_head_norm'],\n",
    "                    torch.tensor(x['flip_tail_embedding']),\n",
    "                ],\n",
    "                dim=0,\n",
    "            ),\n",
    "        }\n",
    "        for x in rows\n",
    "    ]\n",
    "    return pd.DataFrame.from_records(rows_dict)\n",
    "\n",
    "\n",
    "dfs = [hits_to_dataframe(hits) for hits in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n"
     ]
    }
   ],
   "source": [
    "# # An optimized implementation would vectorize the calculation of similarity scores across rows (using a matrix)\n",
    "# def calculate_score(row, query_emb=None, dims=768):\n",
    "#     emb = F.normalize(row[\"embedding\"][:dims], dim=-1)\n",
    "#     return (emb @ query_emb).item()\n",
    "\n",
    "\n",
    "# # You could also add a top-K parameter as a termination condition\n",
    "# def funnel_search(\n",
    "#     df: pd.DataFrame, query_emb, scales=[256, 512, 768], prune_ratio=0.5\n",
    "# ) -> pd.DataFrame:\n",
    "#     for dims in scales:\n",
    "#         # Query vector must be normalized for each new dimensionality\n",
    "#         # query_emb = torch.tensor(search_data[0][:dims] / np.linalg.norm(search_data[0][:dims]))\n",
    "#         emb = torch.tensor(query_emb[:dims] / np.linalg.norm(query_emb[:dims]))\n",
    "\n",
    "#         # Score\n",
    "#         scores = df.apply(\n",
    "#             functools.partial(calculate_score, query_emb=emb, dims=dims), axis=1\n",
    "#         )\n",
    "#         df[\"scores\"] = scores\n",
    "\n",
    "#         # Re-rank\n",
    "#         df.sort_values(by=\"scores\", inplace=True, ascending=False)\n",
    "#         df.head()\n",
    "\n",
    "#         # Prune (in our case, remove half of candidates at each step)\n",
    "#         df = df.head(int(prune_ratio * len(df)))\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "dfs_results = [\n",
    "    {\"query\": query, \"results\": funnel_search(df, query_emb)}\n",
    "    for query, df, query_emb in zip(queries, dfs, flip_search_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A movie about a shark that terrorizes an LA beach. \n",
      " 1                           The Shallows\n",
      "10                 2-Headed Shark Attack\n",
      "49                               Bait 3D\n",
      "17                     Jaws: The Revenge\n",
      "3     The Life Aquatic with Steve Zissou\n",
      "8                                   Jaws\n",
      "93                             Tintorera\n",
      "Name: title, dtype: object \n",
      "\n",
      "An archaeologist searches for ancient artifacts while fighting Nazis. \n",
      " 1            \"Pimpernel\" Smith\n",
      "18               Black Hunters\n",
      "3      Raiders of the Lost Ark\n",
      "48              The Master Key\n",
      "112            My Gun Is Quick\n",
      "43                 The Passage\n",
      "56             The Mole People\n",
      "Name: title, dtype: object \n",
      "\n",
      "Teenagers in detention learn about themselves. \n",
      " 0          Bad Kids Go to Hell\n",
      "23            Band of the Hand\n",
      "48               Take the Lead\n",
      "22                 Silent Fall\n",
      "16     Riot in Juvenile Prison\n",
      "123         Within These Walls\n",
      "29                       Pluto\n",
      "Name: title, dtype: object \n",
      "\n",
      "A teenager fakes illness to get off school and have adventures with two friends. \n",
      " 70                          A Walk to Remember\n",
      "0                               How I Live Now\n",
      "5                                   Unfriended\n",
      "25    Cirque du Freak: The Vampire's Assistant\n",
      "83                                 Last Summer\n",
      "79                                     Contest\n",
      "39                                     Day One\n",
      "Name: title, dtype: object \n",
      "\n",
      "A young couple with a kid look after a hotel during winter and the husband goes insane. \n",
      " 16             Ghostkeeper\n",
      "15          Killing Ground\n",
      "53     Leopard in the Snow\n",
      "54                   Stone\n",
      "113              Afterglow\n",
      "94              Unfaithful\n",
      "19          Always a Bride\n",
      "Name: title, dtype: object \n",
      "\n",
      "Four turtles fight bad guys. \n",
      " 0                      Teenage Mutant Ninja Turtles III\n",
      "63                           TMNT 2: Out of the Shadows\n",
      "3     Teenage Mutant Ninja Turtles II: The Secret of...\n",
      "14                         Teenage Mutant Ninja Turtles\n",
      "2                                          Dreamcatcher\n",
      "5                                        Duck and Cover\n",
      "16    6 Ultra Brothers !The 6 Ultra Brothers vs. the...\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dfs_results:\n",
    "    print(d[\"query\"], \"\\n\", d[\"results\"][:7][\"title\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is much poorer than funnel search or regular search as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Funnel Search Recall Failure for Ferris Bueller's Day Off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why didn't funnel search succeed in retrieving Ferris Bueller's Day Off? Let's examine whether it wasn't in the original candidate list, or was mistakenly filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"A teenager fakes illness to get off school and have adventures with two friends.\"\n",
    "]\n",
    "\n",
    "\n",
    "# Search the database based on input text\n",
    "def embed_search(data):\n",
    "    embeds = model.encode(data)\n",
    "    return [x for x in embeds]\n",
    "\n",
    "instruct_queries = [\"search_query: \" + q.strip() for q in queries]\n",
    "search_data = embed_search(instruct_queries)\n",
    "\n",
    "# Normalize head embeddings\n",
    "head_search = [x[:search_dim] / np.linalg.norm(x[:search_dim]) for x in search_data]\n",
    "\n",
    "# Perform standard vector search on subset of embeddings\n",
    "res = client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=head_search,\n",
    "    anns_field=\"head_embedding\",\n",
    "    limit=256,\n",
    "    output_fields=[\"title\", \"head_embedding\", \"head_norm\", \"tail_embedding\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: A teenager fakes illness to get off school and have adventures with two friends.\n",
      "Row 228: Ferris Bueller's Day Off\n"
     ]
    }
   ],
   "source": [
    "for query, hits in zip(queries, res):\n",
    "    rows = [x['entity'] for x in hits]\n",
    "\n",
    "    print(\"Query:\", query)\n",
    "    for idx, row in enumerate(rows):\n",
    "        if row['title'].strip() == \"Ferris Bueller's Day Off\":\n",
    "            print(f\"Row {idx}: Ferris Bueller's Day Off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the issue was that the initial candidate list was not large enough, or rather, the desired hit is not similar enough to the query at the highest level of granularity. Changing it from `128` to `256` results in successful retrieval. We should form a rule-of-thumb to set the number of candidates on a held-out set to empirically evaluate the trade-off between recall and latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"scores\"] = scores\n",
      "/var/folders/sp/n9dbwjhn4y3dwtr36mlb3_n80000gn/T/ipykernel_78391/1766160193.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by=\"scores\", inplace=True, ascending=False)\n"
     ]
    }
   ],
   "source": [
    "def hits_to_dataframe(hits: pymilvus.client.abstract.Hits) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a Milvus search result to a Pandas dataframe. This function is specific to our data schema.\n",
    "\n",
    "    NOTE: We have to unnormalize head embedding so we can correctly normalize superset Matryoshka embeddings. This\n",
    "    is why we stored head_norm field.\n",
    "    \"\"\"\n",
    "    rows = [x['entity'] for x in hits]\n",
    "    rows_dict = [\n",
    "        {\n",
    "            \"title\": x['title'],\n",
    "            \"embedding\": torch.concat(\n",
    "                [\n",
    "                    torch.tensor(x['head_embedding']) * x['head_norm'],\n",
    "                    torch.tensor(x['tail_embedding']),\n",
    "                ],\n",
    "                dim=0,\n",
    "            ),\n",
    "        }\n",
    "        for x in rows\n",
    "    ]\n",
    "    return pd.DataFrame.from_records(rows_dict)\n",
    "\n",
    "\n",
    "dfs = [hits_to_dataframe(hits) for hits in res]\n",
    "\n",
    "dfs_results = [\n",
    "    {\"query\": query, \"results\": funnel_search(df, query_emb)}\n",
    "    for query, df, query_emb in zip(queries, dfs, search_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A teenager fakes illness to get off school and have adventures with two friends. \n",
      " 137          A Walk to Remember\n",
      "228    Ferris Bueller's Day Off\n",
      "21               How I Live Now\n",
      "32     On the Edge of Innocence\n",
      "77             Bratz: The Movie\n",
      "4                    Unfriended\n",
      "108                  Simon Says\n",
      "Name: title, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in dfs_results:\n",
    "    print(d[\"query\"], \"\\n\", d[\"results\"][:7][\"title\"], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milvus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
