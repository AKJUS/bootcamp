{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/milvus-io/bootcamp/blob/master/bootcamp/tutorials/integration/qa_with_milvus_and_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Using Milvus and Hugging Face\n",
    "\n",
    "A question answering system based on semantic search works by finding the most similar question from a dataset of question-answer pairs for a given query question. Once the most similar question is identified, the corresponding answer from the dataset is considered as the answer for the query. This approach relies on semantic similarity measures to determine the similarity between questions and retrieve relevant answers.\n",
    "\n",
    "This tutorial shows how to build a question answering system using [Hugging Face](https://huggingface.co) as the data loader & embedding generator for data processing and [Milvus](https://milvus.io) as the vector database for semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you begin\n",
    "\n",
    "You need to make sure all required dependencies are installed:\n",
    "\n",
    "- `pymilvus`: a python package works with the vector database service powered by Milvus or Zilliz Cloud.\n",
    "- `datasets`, `transformers`: Hugging Face packages manage data and utilize models.\n",
    "- `torch`: a powerful library provides efficient tensor computation and deep learning tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pymilvus transformers datasets torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To use the updated python packages, you may need to restart the runtime or kernel after installation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "In this section, we will load example question-answer pairs from the Hugging Face Datasets. As a demo, we only take partial data from the validation split of [SQuAD](https://huggingface.co/datasets/rajpurkar/squad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'question', 'answer'],\n",
      "    num_rows: 11\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "DATASET = \"squad\"  # Name of dataset from HuggingFace Datasets\n",
    "INSERT_RATIO = 0.001  # Ratio of example dataset to be inserted\n",
    "\n",
    "data = load_dataset(DATASET, split=\"validation\")\n",
    "# Generates a fixed subset. To generate a random subset, remove the seed.\n",
    "data = data.train_test_split(test_size=INSERT_RATIO, seed=42)[\"test\"]\n",
    "# Clean up the data structure in the dataset.\n",
    "data = data.map(\n",
    "    lambda val: {\"answer\": val[\"answers\"][\"text\"][0]},\n",
    "    remove_columns=[\"id\", \"answers\", \"context\"],\n",
    ")\n",
    "\n",
    "# View summary of example data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate embeddings for questions, you are able to select a text embedding model from Hugging Face Models. In this tutorial, we will use a small sentencce embedding model [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) as example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Private_school',\n",
       "  'question': 'In what year did Massachusetts first require children to be educated in schools?',\n",
       "  'answer': '1852',\n",
       "  'question_embedding': [0.014339025132358074,\n",
       "   0.06589826941490173,\n",
       "   0.06396834552288055,\n",
       "   0.12449634820222855,\n",
       "   -0.019434230402112007,\n",
       "   0.02431458793580532,\n",
       "   -0.08432557433843613,\n",
       "   -0.05138671398162842,\n",
       "   -0.07805464416742325,\n",
       "   0.09302899241447449,\n",
       "   0.135276198387146,\n",
       "   0.0648188591003418,\n",
       "   -0.01741827093064785,\n",
       "   0.003952770493924618,\n",
       "   -0.08166591078042984,\n",
       "   0.09354530274868011,\n",
       "   0.0182030089199543,\n",
       "   0.004858741536736488,\n",
       "   0.02897047996520996,\n",
       "   0.01158266980201006,\n",
       "   0.003501549595966935,\n",
       "   0.009978513233363628,\n",
       "   -0.05116446316242218,\n",
       "   0.024345267564058304,\n",
       "   0.09897436946630478,\n",
       "   0.09035474807024002,\n",
       "   0.08834364265203476,\n",
       "   -0.037395790219306946,\n",
       "   -0.029011476784944534,\n",
       "   0.022494154050946236,\n",
       "   -0.006402186118066311,\n",
       "   -0.10760119557380676,\n",
       "   0.09280959516763687,\n",
       "   0.02133854851126671,\n",
       "   0.05904597416520119,\n",
       "   0.00937202200293541,\n",
       "   0.21006059646606445,\n",
       "   0.059382546693086624,\n",
       "   -0.01494697853922844,\n",
       "   0.010121198371052742,\n",
       "   -0.042923495173454285,\n",
       "   -0.04681266099214554,\n",
       "   0.06653677672147751,\n",
       "   0.02190573327243328,\n",
       "   -0.029133997857570648,\n",
       "   0.0049314433708786964,\n",
       "   -0.018513448536396027,\n",
       "   0.0027959696017205715,\n",
       "   0.011040791869163513,\n",
       "   0.02861822582781315,\n",
       "   -0.03118242137134075,\n",
       "   -0.011293049901723862,\n",
       "   -0.0070234667509794235,\n",
       "   -0.019396308809518814,\n",
       "   -0.03641491010785103,\n",
       "   0.054664649069309235,\n",
       "   -0.022166313603520393,\n",
       "   0.06346654146909714,\n",
       "   -0.02750234492123127,\n",
       "   0.034178726375103,\n",
       "   -0.1076311245560646,\n",
       "   -0.03963033854961395,\n",
       "   -0.035775210708379745,\n",
       "   0.013375434093177319,\n",
       "   0.00509216682985425,\n",
       "   0.017022913321852684,\n",
       "   -0.07020150870084763,\n",
       "   -0.07844817638397217,\n",
       "   0.0019036357989534736,\n",
       "   0.04317513480782509,\n",
       "   0.030161837115883827,\n",
       "   0.010257985442876816,\n",
       "   0.008191527798771858,\n",
       "   -0.0119168097153306,\n",
       "   -0.029051553457975388,\n",
       "   0.012927955947816372,\n",
       "   -0.004916873760521412,\n",
       "   0.08163794875144958,\n",
       "   0.0439811646938324,\n",
       "   -0.057943325489759445,\n",
       "   0.0022056144662201405,\n",
       "   0.02731304056942463,\n",
       "   -0.037630774080753326,\n",
       "   -0.02759927697479725,\n",
       "   0.029253924265503883,\n",
       "   -0.03598169609904289,\n",
       "   -0.03824399784207344,\n",
       "   0.002793595427647233,\n",
       "   0.07469785958528519,\n",
       "   -0.017568007111549377,\n",
       "   0.03969186544418335,\n",
       "   -0.027315380051732063,\n",
       "   -0.0816231295466423,\n",
       "   0.026097116991877556,\n",
       "   0.057501453906297684,\n",
       "   -0.07439840584993362,\n",
       "   -0.1055254340171814,\n",
       "   -0.02838391438126564,\n",
       "   -0.014170043170452118,\n",
       "   -0.0015569915995001793,\n",
       "   -0.07380989193916321,\n",
       "   -0.038953930139541626,\n",
       "   0.03413432836532593,\n",
       "   0.1241149753332138,\n",
       "   -0.014252784661948681,\n",
       "   0.015376598574221134,\n",
       "   0.009212302044034004,\n",
       "   -0.057595983147621155,\n",
       "   -0.005694312043488026,\n",
       "   -0.0054076965898275375,\n",
       "   0.025905698537826538,\n",
       "   -0.01935477741062641,\n",
       "   -0.005938223097473383,\n",
       "   0.052570000290870667,\n",
       "   0.02078522928059101,\n",
       "   -0.04835842549800873,\n",
       "   0.10358233004808426,\n",
       "   -0.0341142863035202,\n",
       "   0.026903871446847916,\n",
       "   -0.0033970095682889223,\n",
       "   0.03181617334485054,\n",
       "   -0.03680907189846039,\n",
       "   -0.04832909256219864,\n",
       "   -0.1149400845170021,\n",
       "   -0.07713524997234344,\n",
       "   -0.035198312252759933,\n",
       "   -0.10089436918497086,\n",
       "   -2.105524910041742e-33,\n",
       "   -0.013159321621060371,\n",
       "   -0.05325843021273613,\n",
       "   -0.007703737821429968,\n",
       "   0.09163380414247513,\n",
       "   -0.05312276631593704,\n",
       "   -0.03933641314506531,\n",
       "   0.02169172838330269,\n",
       "   -0.12405183911323547,\n",
       "   0.019319849088788033,\n",
       "   -0.09812074154615402,\n",
       "   0.03389574959874153,\n",
       "   -0.05489164590835571,\n",
       "   0.014886590652167797,\n",
       "   -0.024623645469546318,\n",
       "   0.05004822462797165,\n",
       "   0.01730850711464882,\n",
       "   -0.03825455531477928,\n",
       "   0.08455520868301392,\n",
       "   0.030011584982275963,\n",
       "   0.011057838797569275,\n",
       "   -0.037529610097408295,\n",
       "   -0.05071919411420822,\n",
       "   -0.016466744244098663,\n",
       "   -0.0808337926864624,\n",
       "   -0.07511809468269348,\n",
       "   0.02311760187149048,\n",
       "   0.03168448433279991,\n",
       "   -0.01333296112716198,\n",
       "   0.05840163677930832,\n",
       "   -0.006920496467500925,\n",
       "   0.12264736741781235,\n",
       "   -0.028350720182061195,\n",
       "   -0.024227188900113106,\n",
       "   -0.03392912447452545,\n",
       "   0.007026601582765579,\n",
       "   0.013849477283656597,\n",
       "   0.028375379741191864,\n",
       "   -0.04562440142035484,\n",
       "   0.03172976151108742,\n",
       "   -0.035421937704086304,\n",
       "   0.06133498623967171,\n",
       "   -0.03757933899760246,\n",
       "   0.11214828491210938,\n",
       "   0.03965345770120621,\n",
       "   0.00301483366638422,\n",
       "   0.020354002714157104,\n",
       "   -0.06334848701953888,\n",
       "   -0.0013640634715557098,\n",
       "   0.05261427164077759,\n",
       "   0.03070572391152382,\n",
       "   0.010877493768930435,\n",
       "   -0.031180698424577713,\n",
       "   -0.11453939229249954,\n",
       "   -0.10946774482727051,\n",
       "   0.02442561276257038,\n",
       "   -0.0150124067440629,\n",
       "   -0.05922917276620865,\n",
       "   0.08681073784828186,\n",
       "   -0.044746033847332,\n",
       "   -0.029202952980995178,\n",
       "   -0.052518606185913086,\n",
       "   0.029297305271029472,\n",
       "   0.031239215284585953,\n",
       "   -0.041330594569444656,\n",
       "   -0.014262533746659756,\n",
       "   -0.0005018757656216621,\n",
       "   0.023170240223407745,\n",
       "   0.03793271631002426,\n",
       "   0.09360039979219437,\n",
       "   -0.023973658680915833,\n",
       "   0.03349245712161064,\n",
       "   0.03310176730155945,\n",
       "   -0.06407491862773895,\n",
       "   0.026995636522769928,\n",
       "   -0.023986278101801872,\n",
       "   -0.0014470909954980016,\n",
       "   0.07127188891172409,\n",
       "   -0.05994250252842903,\n",
       "   0.03264152258634567,\n",
       "   0.011522015556693077,\n",
       "   0.035296399146318436,\n",
       "   -0.05484265834093094,\n",
       "   -0.03832615911960602,\n",
       "   0.021724658086895943,\n",
       "   -0.0060281469486653805,\n",
       "   -0.013768195174634457,\n",
       "   0.003175197634845972,\n",
       "   0.0544171966612339,\n",
       "   0.049840301275253296,\n",
       "   -0.008465572260320187,\n",
       "   0.02766692452132702,\n",
       "   -0.04515276476740837,\n",
       "   -0.07256209850311279,\n",
       "   0.0016269945772364736,\n",
       "   -0.03405643254518509,\n",
       "   -4.948031329790294e-34,\n",
       "   -0.0031053833663463593,\n",
       "   0.025888986885547638,\n",
       "   -0.022763337939977646,\n",
       "   0.02832895517349243,\n",
       "   -0.047932177782058716,\n",
       "   -0.026791710406541824,\n",
       "   0.04852898791432381,\n",
       "   -0.01650378480553627,\n",
       "   0.02860167622566223,\n",
       "   -0.038634952157735825,\n",
       "   -0.033388666808605194,\n",
       "   -0.03137075528502464,\n",
       "   0.031233379617333412,\n",
       "   0.019169922918081284,\n",
       "   0.013447176665067673,\n",
       "   -0.029256761074066162,\n",
       "   -0.012548183090984821,\n",
       "   -0.04534417390823364,\n",
       "   0.041860684752464294,\n",
       "   -0.027822569012641907,\n",
       "   0.0372614860534668,\n",
       "   0.028951531276106834,\n",
       "   -0.0652388334274292,\n",
       "   0.06227545440196991,\n",
       "   0.009335150942206383,\n",
       "   -0.03351680561900139,\n",
       "   -0.13269658386707306,\n",
       "   0.037656042724847794,\n",
       "   -0.08043345808982849,\n",
       "   0.00235629896633327,\n",
       "   0.07965125888586044,\n",
       "   0.0845644623041153,\n",
       "   0.004607722163200378,\n",
       "   0.06666402518749237,\n",
       "   -0.03813115134835243,\n",
       "   -0.009752584621310234,\n",
       "   -0.04955795034766197,\n",
       "   0.0831562727689743,\n",
       "   -0.0381799191236496,\n",
       "   0.06214286759495735,\n",
       "   0.02353006787598133,\n",
       "   -0.0835784375667572,\n",
       "   -0.028340274468064308,\n",
       "   0.06697361916303635,\n",
       "   0.006053093355149031,\n",
       "   0.059180036187171936,\n",
       "   0.09626568108797073,\n",
       "   0.03236861154437065,\n",
       "   0.028357265517115593,\n",
       "   0.051316097378730774,\n",
       "   -0.09767436236143112,\n",
       "   0.05497896671295166,\n",
       "   -0.0005836611962877214,\n",
       "   -0.02258099801838398,\n",
       "   0.012308496050536633,\n",
       "   -0.024226685985922813,\n",
       "   0.005697558633983135,\n",
       "   -0.004606139846146107,\n",
       "   0.007538756355643272,\n",
       "   0.06286327540874481,\n",
       "   0.056008730083703995,\n",
       "   -0.06817635148763657,\n",
       "   -0.08446035534143448,\n",
       "   -0.06237947940826416,\n",
       "   -0.02986907586455345,\n",
       "   0.01938287913799286,\n",
       "   -0.04762266203761101,\n",
       "   0.021781442686915398,\n",
       "   -0.017814310267567635,\n",
       "   0.004966909531503916,\n",
       "   0.06900834292173386,\n",
       "   0.0125663373619318,\n",
       "   0.10617635399103165,\n",
       "   -0.03737768903374672,\n",
       "   -0.022894704714417458,\n",
       "   0.04068702086806297,\n",
       "   0.04673757031559944,\n",
       "   0.011554424650967121,\n",
       "   -0.07566538453102112,\n",
       "   0.022234588861465454,\n",
       "   -0.12440325319766998,\n",
       "   -0.023369871079921722,\n",
       "   -0.04229593276977539,\n",
       "   -3.607330654631369e-05,\n",
       "   -0.03660031780600548,\n",
       "   -0.02350945770740509,\n",
       "   0.023304246366024017,\n",
       "   -0.08961540460586548,\n",
       "   0.0003358897229190916,\n",
       "   -0.019766854122281075,\n",
       "   -0.01972701959311962,\n",
       "   -0.02038516104221344,\n",
       "   0.03294171020388603,\n",
       "   -0.06208743155002594,\n",
       "   -0.12511849403381348,\n",
       "   -1.814340677697146e-08,\n",
       "   0.03579665720462799,\n",
       "   0.04684377461671829,\n",
       "   -0.02147405594587326,\n",
       "   0.03612668439745903,\n",
       "   0.057244934141635895,\n",
       "   0.012117805890738964,\n",
       "   0.0019518494373187423,\n",
       "   0.014309120364487171,\n",
       "   0.022054336965084076,\n",
       "   0.02634318731725216,\n",
       "   -0.11790483444929123,\n",
       "   0.006679957266896963,\n",
       "   0.05211051180958748,\n",
       "   -0.010516999289393425,\n",
       "   0.0695006251335144,\n",
       "   -0.008465232327580452,\n",
       "   -0.020176487043499947,\n",
       "   -0.005654269363731146,\n",
       "   -0.025283537805080414,\n",
       "   0.03312133252620697,\n",
       "   0.03413303941488266,\n",
       "   -0.02371249720454216,\n",
       "   0.013005527667701244,\n",
       "   0.02811620570719242,\n",
       "   -0.05552487447857857,\n",
       "   0.01436573825776577,\n",
       "   0.03246351331472397,\n",
       "   0.03226830065250397,\n",
       "   -0.061139822006225586,\n",
       "   0.06711037456989288,\n",
       "   0.054952122271060944,\n",
       "   0.04321783781051636,\n",
       "   -0.028958620503544807,\n",
       "   -0.05073670670390129,\n",
       "   -0.03370021656155586,\n",
       "   -0.018544979393482208,\n",
       "   -0.05051993951201439,\n",
       "   0.04795075207948685,\n",
       "   -0.007098092697560787,\n",
       "   -0.1068258211016655,\n",
       "   -0.005060961470007896,\n",
       "   0.026501666754484177,\n",
       "   0.028995802626013756,\n",
       "   0.03767790272831917,\n",
       "   0.05707642063498497,\n",
       "   0.09026692807674408,\n",
       "   -0.07373545318841934,\n",
       "   0.0788806900382042,\n",
       "   0.02591443620622158,\n",
       "   0.0790964737534523,\n",
       "   -0.05694793537259102,\n",
       "   -0.0062374575063586235,\n",
       "   -0.049288421869277954,\n",
       "   -0.08188693225383759,\n",
       "   0.009361925534904003,\n",
       "   -0.06141914427280426,\n",
       "   0.07033951580524445,\n",
       "   -0.0667513757944107,\n",
       "   -0.03697584941983223,\n",
       "   -0.0646183118224144,\n",
       "   0.05784734711050987,\n",
       "   0.04699626937508583,\n",
       "   0.030394842848181725,\n",
       "   0.025646695867180824]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "MODEL = (\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"  # Name of model from HuggingFace Models\n",
    ")\n",
    "INFERENCE_BATCH_SIZE = 64  # Batch size of model inference\n",
    "\n",
    "# Load tokenizer & model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModel.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "def encode_text(batch):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(\n",
    "        batch[\"question\"], padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    token_embeddings = model_output[0]\n",
    "    attention_mask = encoded_input[\"attention_mask\"]\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    sentence_embeddings = torch.sum(\n",
    "        token_embeddings * input_mask_expanded, 1\n",
    "    ) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    # Normalize embeddings\n",
    "    batch[\"question_embedding\"] = torch.nn.functional.normalize(\n",
    "        sentence_embeddings, p=2, dim=1\n",
    "    )\n",
    "    return batch\n",
    "\n",
    "\n",
    "data = data.map(encode_text, batched=True, batch_size=INFERENCE_BATCH_SIZE)\n",
    "data_list = data.to_list()\n",
    "\n",
    "# Preview prepared data (the first entity)\n",
    "data_list[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert data\n",
    "\n",
    "Now we have question-answer pairs ready with question embeddings. The next step is to insert them into the vector database.\n",
    "\n",
    "We will first need to connect to Milvus service and create a Milvus collection. This section will use [Milvus Lite](https://milvus.io/docs/milvus_lite.md) as example. If you want to use other types of Milvus or [Zilliz Cloud](https://zilliz.com), please make sure you have started the service and connect with your own URI & credentials. You are also able to change parameters to customize your collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "\n",
    "MILVUS_URI = \"./huggingface_milvus_test.db\"  # Connection URI\n",
    "COLLECTION_NAME = \"huggingface_test\"  # Collection name\n",
    "DIMENSION = 384  # Embedding dimension depending on model\n",
    "\n",
    "milvus_client = MilvusClient(MILVUS_URI)\n",
    "milvus_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    dimension=DIMENSION,\n",
    "    auto_id=True,  # Enable auto id\n",
    "    enable_dynamic_field=True,  # Enable dynamic fields\n",
    "    vector_field_name=\"question_embedding\",  # Map vector field name and embedding column in dataset\n",
    "    consistency_level=\"Strong\",  # To enable search with latest data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert all data into the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'insert_count': 11,\n",
       " 'ids': [450072488481390592, 450072488481390593, 450072488481390594, 450072488481390595, 450072488481390596, 450072488481390597, 450072488481390598, 450072488481390599, 450072488481390600, 450072488481390601, 450072488481390602],\n",
       " 'cost': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "milvus_client.insert(collection_name=COLLECTION_NAME, data=data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions\n",
    "\n",
    "Once all the data is inserted into Milvus, we can ask questions and see what the closest answers are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is LGM?\n",
      "{'answer': 'Last Glacial Maximum', 'score': 0.956273078918457, 'original question': 'What does LGM stands for?'}\n",
      "{'answer': 'coordinate the response to the embargo', 'score': 0.2120140939950943, 'original question': 'Why was this short termed organization created?'}\n",
      "{'answer': '\"Reducibility Among Combinatorial Problems\"', 'score': 0.1945795714855194, 'original question': 'What is the paper written by Richard Karp in 1972 that ushered in a new era of understanding between intractability and NP-complete problems?'}\n",
      "\n",
      "\n",
      "Question: When did Massachusetts first mandate that children be educated in schools?\n",
      "{'answer': '1852', 'score': 0.9709997177124023, 'original question': 'In what year did Massachusetts first require children to be educated in schools?'}\n",
      "{'answer': 'several regional colleges and universities', 'score': 0.34164726734161377, 'original question': 'In 1890, who did the university decide to team up with?'}\n",
      "{'answer': '1962', 'score': 0.1931006908416748, 'original question': 'When were stromules discovered?'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = {\n",
    "    \"question\": [\n",
    "        \"What is LGM?\",\n",
    "        \"When did Massachusetts first mandate that children be educated in schools?\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Generate question embeddings\n",
    "question_embeddings = [v.tolist() for v in encode_text(questions)[\"question_embedding\"]]\n",
    "\n",
    "# Search across Milvus\n",
    "search_results = milvus_client.search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    data=question_embeddings,\n",
    "    limit=3,  # How many search results to output\n",
    "    output_fields=[\"answer\", \"question\"],  # Include these fields in search results\n",
    ")\n",
    "\n",
    "# Print out results\n",
    "for q, res in zip(questions[\"question\"], search_results):\n",
    "    print(\"Question:\", q)\n",
    "    for r in res:\n",
    "        print(\n",
    "            {\n",
    "                \"answer\": r[\"entity\"][\"answer\"],\n",
    "                \"score\": r[\"distance\"],\n",
    "                \"original question\": r[\"entity\"][\"question\"],\n",
    "            }\n",
    "        )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "develop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
